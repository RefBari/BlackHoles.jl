<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Sanity Checks · BlackHoles.jl</title><meta name="title" content="Sanity Checks · BlackHoles.jl"/><meta property="og:title" content="Sanity Checks · BlackHoles.jl"/><meta property="twitter:title" content="Sanity Checks · BlackHoles.jl"/><meta name="description" content="Documentation for BlackHoles.jl."/><meta property="og:description" content="Documentation for BlackHoles.jl."/><meta property="twitter:description" content="Documentation for BlackHoles.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">BlackHoles.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Conservative Dynamics</span><ul><li><a class="tocitem" href="../newtonian-metric/">Physics of Newtonian Metric</a></li><li><a class="tocitem" href="../schwarzschild-metric/">Physics of Schwarzschild Metric</a></li><li><a class="tocitem" href="../orbits/">Simulating Orbits in Schwarzschild Metric</a></li><li><a class="tocitem" href="../waveforms/">Quadrupole Approximation: Orbits to Gravitational Wave</a></li><li><a class="tocitem" href="../higher_modes/">Adding Higher Order Modes</a></li><li><a class="tocitem" href="../inverse_problem/">Fundamentals of Neural Networks</a></li><li class="is-active"><a class="tocitem" href>Sanity Checks</a></li></ul></li><li><span class="tocitem">Dissipative Dynamics</span><ul><li><a class="tocitem" href="../GENERIC/">Theory: GENERIC Formalism</a></li><li><a class="tocitem" href="../dissipative_orbits/">Simulating Orbits with GENERIC</a></li><li><a class="tocitem" href="../full_inverse_problem/">Dissipative Case: Waves to Orbits</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Conservative Dynamics</a></li><li class="is-active"><a href>Sanity Checks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Sanity Checks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/RefBari/BlackHoles.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/RefBari/BlackHoles.jl/blob/main/docs/src/guide/sanity_checks.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Sanity-Checks"><a class="docs-heading-anchor" href="#Sanity-Checks">Sanity Checks</a><a id="Sanity-Checks-1"></a><a class="docs-heading-anchor-permalink" href="#Sanity-Checks" title="Permalink"></a></h1><p>We can run several sanity checks to ensure that our Neural ODE is indeed learning the Schwarzschild Metric. In this module, we examine the following sanity checks: </p><div class="admonition is-info" id="Use-Schwarzchild-Metric-as-Base-Model-(Multiplicative-Corrections)-96f6b8d841871844"><header class="admonition-header">Use Schwarzchild Metric as Base Model (Multiplicative Corrections)<a class="admonition-anchor" href="#Use-Schwarzchild-Metric-as-Base-Model-(Multiplicative-Corrections)-96f6b8d841871844" title="Permalink"></a></header><div class="admonition-body"><p>If we use the Schwarzschild Metric as the base model for the Neural ODE, there should be nothing for the network to learn. We are considering training data generated by using schwarzschild geodesics (no dissipation, only conservative dynamics). For this particular sanity check, we consider only circular orbits, the simplest kind of orbit. We can frame this in one of two ways. We can have multiplicative corrections as follows:</p><pre><code class="language-julia hljs"># Base Metric: Schwarzschild Metric
  g = [
        -f^(-1)*f_tt_NN_correction 0 0 0;
        0 f*f_rr_NN_correction 0 0;
        0 0 0 0;
        0 0 0 r^(-2)*f_ϕϕ_NN_correction
    ]</code></pre></div></div><div class="admonition is-info" id="Use-Schwarzchild-Metric-as-Base-Model-(Additive-Corrections)-e025c948a802c47d"><header class="admonition-header">Use Schwarzchild Metric as Base Model (Additive Corrections)<a class="admonition-anchor" href="#Use-Schwarzchild-Metric-as-Base-Model-(Additive-Corrections)-e025c948a802c47d" title="Permalink"></a></header><div class="admonition-body"><p>In the multiplicative case, the corrections that the neural network should learn is 1. Alternatively, we can have additive corrections as follows:  </p><pre><code class="language-julia hljs"># Base Metric: Schwarzschild Metric
  g = [
        -f^(-1)+f_tt_NN_correction 0 0 0;
        0 f+f_rr_NN_correction 0 0;
        0 0 0 0;
        0 0 0 r^(-2)+f_ϕϕ_NN_correction
    ]</code></pre><p>The additive corrections should be 0 if the neural network learns &quot;nothing&quot; correctly. Ideally, this sanity check would be the simplest thing for the neural network to do: in the multiplicative correction case, it should learn no more than 1. Likewise in the additive correction case, it should learn simply 0. </p></div></div><p>First of all, when conducting sanity checks, you want to strip the problem of all its complexity. For starters, we make the neural network extremely simple.</p><pre><code class="language-julia hljs">NN_Conservative = Chain(
    Dense(1, 1, tanh), # Input: r only
    Dense(1, 1, tanh),
    Dense(1, 3), # Output: Corrections for [g^tt, g^rr, g^ϕϕ]
)</code></pre><p>We will treat the corrections as multiplicative for this first case, as follows: </p><pre><code class="language-julia hljs">g = [
      -f^(-1)*f_tt_NN_correction 0 0 0;
      0 f*f_rr_NN_correction 0 0;
      0 0 0 0;
      0 0 0 r^(-2)*f_ϕϕ_NN_correction
    ]</code></pre><p>This Neural Network has only 10 parameters: </p><pre><code class="language-julia hljs">Chain(
    layer_1 = Dense(1 =&gt; 1, tanh),      # 2 parameters
    layer_2 = Dense(1 =&gt; 1, tanh),      # 2 parameters
    layer_3 = Dense(1 =&gt; 3),            # 6 parameters
 )        # Total: 10 parameters,
          #        plus 0 states.</code></pre><p>We initialize the NN weights and biases for the hidden layers, except for the final layer: </p><pre><code class="language-julia hljs">for (i, layer) in enumerate(NN_Conservative_params)
    if ~isempty(layer)
        if i == length(NN_Conservative_params)  # Final layer
            layer.weight .= 0
            layer.bias .= 0  # Force output near 0
        else  # Hidden layers
            layer.weight .= 0.1 * randn(rng, eltype(layer.weight), size(layer.weight))
            layer.bias .= 0.1 * randn(rng, eltype(layer.bias), size(layer.bias))
        end
    end
end</code></pre><p>When we do this, here&#39;s what we find for the NN parameters (conservative NN) after initialization (but <em>before</em> training): </p><ul><li><code>layer_1 = (weight = [0.23716215388290493;;], bias = [0.12095544082478167])</code></li><li><code>layer_2 = (weight = [0.03983070751935526;;], bias = [-0.16211640815748582])</code></li><li><code>layer_3 = (weight = [0.0; 0.0; 0.0;;], bias = [0.0, 0.0, 0.0]))</code></li></ul><p>When you plot the initial solution to the ODEs, we find exact agreement (as expected, since our base model is the Schwarzschild metric!)</p><p><img src="../CircularOrbit.png" alt="CircularOrbit"/></p><p>Now when we plot the predicted metrics and orbit after initialization (but <strong>before</strong> training), we find exact agreement, as expected:</p><p><img src="../3Corrections_PreTraining.png" alt="3Corrections_PreTraining"/></p><p>Our loss function is simply a mean-squared error between the predicted and true waveform: </p><pre><code class="language-julia hljs">function loss(NN_params; saveat=tsteps)
    tspan = (saveat[1],saveat[end])
    pred_soln = solve(remake(prob_nn_dual, p = NN_params, tspan=tspan), Tsit5(),
                            saveat = saveat, dt = dt, adaptive=false, verbose = false, sensealg=BacksolveAdjoint(checkpointing=true))
    pred_waveform_real, pred_waveform_imag = compute_waveform(dt_data, pred_soln, mass_ratio)

    loss = ( sum(abs2, waveform_real_ecc .- pred_waveform_real))
    return loss
end</code></pre><p>When we run our loss function on just the initial solution, we get <code>2.25e-7</code>. Now we run the training process, after which we obtain these results: </p><p><img src="../3Correction_PostTraining.png" alt="3Correction_PostTraining"/></p><p>I ran through 4 iterations: <code>optimization_increments = [1, 2, 12, 20]</code>. Over these four iterations, here&#39;s how the weights and biases changed over time: </p><div class="admonition is-warning" id="Iteration-#1-Weights-and-Biases-44a3aaf0b700a1e4"><header class="admonition-header">Iteration #1 Weights &amp; Biases<a class="admonition-anchor" href="#Iteration-#1-Weights-and-Biases-44a3aaf0b700a1e4" title="Permalink"></a></header><div class="admonition-body"><ul><li><code>layer_1 = (weight = [0.2371808185363373;], bias = [0.120935736109229])</code></li><li><code>layer_2 = (weight = [0.03982656907286769;], bias = [-0.16213122300485072])</code> </li><li><code>layer_3 = (weight = [-1.821512530359164e-5; -1.0175274439859679e-5; 8.716160136546225e-7;], bias = [9.8766420116128e-6, 5.723394566465591e-6, 3.481497345221852e-6]))</code></li></ul></div></div><div class="admonition is-warning" id="Iteration-#2-Weights-and-Biases-787978605b3750a8"><header class="admonition-header">Iteration #2 Weights &amp; Biases<a class="admonition-anchor" href="#Iteration-#2-Weights-and-Biases-787978605b3750a8" title="Permalink"></a></header><div class="admonition-body"><ul><li><code>layer_1 = (weight = [0.23718676030213381;], bias = [0.12092385329517617])</code></li><li><code>layer_2 = (weight = [0.03983349725191167;], bias = [-0.1621299634300346])</code></li><li><code>layer_3 = (weight = [-2.487679834028046e-5; -2.887058705740126e-5; 1.0738885848191339e-6;], bias = [-4.71782709892314e-6, 7.837322991384513e-6, 2.537287450937874e-6]))</code></li></ul></div></div><div class="admonition is-warning" id="Iteration-#12-Weights-and-Biases-758fc06b83628d09"><header class="admonition-header">Iteration #12 Weights &amp; Biases<a class="admonition-anchor" href="#Iteration-#12-Weights-and-Biases-758fc06b83628d09" title="Permalink"></a></header><div class="admonition-body"><ul><li><code>layer_1 = (weight = [0.2371894925389875;], bias = [0.12093772915528389])</code></li><li><code>layer_2 = (weight = [0.03983157793305357;], bias = [-0.16213630211015895])</code></li><li><code>layer_3 = (weight = [-1.6052012110502056e-5; -3.96908865801902e-5; -9.619462849749647e-6;], bias = [-2.1939207002792404e-5, 1.500639545614688e-6, -2.168304595713335e-5]))</code></li></ul></div></div><div class="admonition is-warning" id="Iteration-#20-Weights-and-Biases-e824e14066a17f9a"><header class="admonition-header">Iteration #20 Weights &amp; Biases<a class="admonition-anchor" href="#Iteration-#20-Weights-and-Biases-e824e14066a17f9a" title="Permalink"></a></header><div class="admonition-body"><ul><li><code>layer_1 = (weight = [0.23718368381374658;], bias = [0.12094224166402442])</code></li><li><code>layer_2 = (weight = [0.03983587381877536;], bias = [-0.16213807102352437])</code></li><li><code>layer_3 = (weight = [-9.10753409970219e-6; -4.110947128717602e-5; -1.749976849031467e-5;], bias = [-1.7950002563821174e-5, 1.4704911668732934e-5, -1.9016787781020368e-5]))</code></li></ul></div></div><p>Here are the loss function and state variables post-training for the sanity check: </p><p><img src="../State_Variables_PostTraining.png" alt="State_Variables_PostTraining"/></p><p><img src="../LossFunction_PostTraining.png" alt="LossFunction_PostTraining"/></p><p>After printing <code>f_tt_pred</code>, <code>f_rr_pred</code>, and <code>f_\phi\phi_pred</code>, the corrections to the <span>$g^{tt}, g^{rr}, g^{\phi\phi}$</span>, we find: </p><pre><code class="language-julia hljs">julia&gt; f_tt_pred
400-element Vector{Any}:
 0.9999831633432387
 0.999983162958138
 0.9999831626034161
 0.9999831622767038
 0.9999831619758125
 0.9999831616987213
 0.999983161443564
 ⋮
 0.9999831584900172
 0.9999831584900172
 0.9999831584900172
 0.9999831584900172
 0.9999831584900172
 0.9999831584900172</code></pre><pre><code class="language-julia hljs">f_rr_pred
400-element Vector{Any}:
 1.0000197298726115
 1.0000197281342853
 1.0000197265330875
 1.0000197250583238
 1.000019723700115
 1.0000197224493381
 1.0000197212975706
 ⋮
 1.000019707965401
 1.000019707965401
 1.000019707965401
 1.000019707965401
 1.000019707965401
 1.000019707965401</code></pre><pre><code class="language-julia hljs">f_pp_pred
400-element Vector{Any}:
 0.9999831223324658
 0.99998312159251
 0.9999831209109258
 0.9999831202831609
 0.9999831197050103
 0.9999831191725903
 0.9999831186823158
 ⋮
 0.9999831130071919
 0.9999831130071919
 0.9999831130071919
 0.9999831130071919
 0.9999831130071919
 0.9999831130071919</code></pre><p>Thus, the sanity check has been passed for multiplicative corrections for a circular orbit! Now we consider additive corrections!</p><pre><code class="language-julia hljs"># Base Metric: Schwarzschild Metric
g = [
        -f^(-1)+f_tt_NN_correction 0 0 0;
        0 f+f_rr_NN_correction 0 0;
        0 0 0 0;
        0 0 0 r^(-2)+f_ϕϕ_NN_correction
    ]</code></pre><p>When we run the sanity check for additive corrections with three corrections for <span>$g^{tt}, g^{rr}, g^{\phi\phi}$</span>, here are the results: </p><p><img src="../AdditiveCorrections_3Terms.png" alt="AdditiveCorrections_3Terms"/></p><p>Now if we return only two corrections, for <span>$g^{rr}$</span> and <span>$g^{\phi\phi}$</span> and lock in <span>$g^{tt}$</span>, we obtain</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../inverse_problem/">« Fundamentals of Neural Networks</a><a class="docs-footer-nextpage" href="../GENERIC/">Theory: GENERIC Formalism »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.0 on <span class="colophon-date" title="Monday 17 November 2025 06:21">Monday 17 November 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
