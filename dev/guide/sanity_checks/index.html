<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Sanity Checks · BlackHoles.jl</title><meta name="title" content="Sanity Checks · BlackHoles.jl"/><meta property="og:title" content="Sanity Checks · BlackHoles.jl"/><meta property="twitter:title" content="Sanity Checks · BlackHoles.jl"/><meta name="description" content="Documentation for BlackHoles.jl."/><meta property="og:description" content="Documentation for BlackHoles.jl."/><meta property="twitter:description" content="Documentation for BlackHoles.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">BlackHoles.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Conservative Dynamics</span><ul><li><a class="tocitem" href="../newtonian-metric/">Physics of Newtonian Metric</a></li><li><a class="tocitem" href="../schwarzschild-metric/">Physics of Schwarzschild Metric</a></li><li><a class="tocitem" href="../orbits/">Simulating Orbits in Schwarzschild Metric</a></li><li><a class="tocitem" href="../waveforms/">Quadrupole Approximation: Orbits to Gravitational Wave</a></li><li><a class="tocitem" href="../higher_modes/">Adding Higher Order Modes</a></li><li><a class="tocitem" href="../inverse_problem/">Fundamentals of Neural Networks</a></li></ul></li><li><span class="tocitem">Dissipative Dynamics</span><ul><li><a class="tocitem" href="../GENERIC/">Theory: GENERIC Formalism</a></li><li><a class="tocitem" href="../dissipative_orbits/">Simulating Orbits with GENERIC</a></li><li><a class="tocitem" href="../full_inverse_problem/">Dissipative Case: Waves to Orbits</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Sanity Checks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Sanity Checks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/RefBari/BlackHoles.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/RefBari/BlackHoles.jl/blob/main/docs/src/guide/sanity_checks.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Sanity-Checks"><a class="docs-heading-anchor" href="#Sanity-Checks">Sanity Checks</a><a id="Sanity-Checks-1"></a><a class="docs-heading-anchor-permalink" href="#Sanity-Checks" title="Permalink"></a></h1><p>We can run several sanity checks to ensure that our Neural ODE is indeed learning the Schwarzschild Metric. In this module, we examine the following sanity checks: </p><div class="admonition is-info" id="Use-Schwarzchild-Metric-as-Base-Model-bd419e964a624876"><header class="admonition-header">Use Schwarzchild Metric as Base Model<a class="admonition-anchor" href="#Use-Schwarzchild-Metric-as-Base-Model-bd419e964a624876" title="Permalink"></a></header><div class="admonition-body"><p>If we use the Schwarzschild Metric as the base model for the Neural ODE, there should be nothing for the network to learn. We are considering training data generated by using schwarzschild geodesics (no dissipation, only conservative dynamics). For this particular sanity check, we consider only circular orbits, the simplest kind of orbit. We can frame this in one of two ways. We can have multiplicative corrections as follows:</p><pre><code class="language-julia hljs"># Base Metric: Schwarzschild Metric
  g = [
        -f^(-1)*f_tt_NN_correction 0 0 0;
        0 f*f_rr_NN_correction 0 0;
        0 0 0 0;
        0 0 0 r^(-2)*f_ϕϕ_NN_correction
    ]</code></pre></div></div><p>In the multiplicative case, the corrections that the neural network should learn is 1. Alternatively, we can have additive corrections as follows:  </p><pre><code class="language-julia hljs">    # Base Metric: Schwarzschild Metric
      g = [
            -f^(-1)+f_tt_NN_correction 0 0 0;
            0 f+f_rr_NN_correction 0 0;
            0 0 0 0;
            0 0 0 r^(-2)+f_ϕϕ_NN_correction
        ]
    ```
    The additive corrections should be 0 if the neural network learns &quot;nothing&quot; correctly. Ideally, this sanity check would be the simplest thing for the neural network to do: in the multiplicative correction case, it should learn no more than 1. Likewise in the additive correction case, it should learn simply 0. 

It turns out, quite amazingly, that the neural network fails this sanity check. Let me go step-by-step through the story. 

First of all, when conducting sanity checks, you want to strip the problem of all its complexity. For starters, we make the neural network extremely simple.
</code></pre><p>julia NN_Conservative = Chain(     Dense(1, 1, tanh), # Input: r only     Dense(1, 1, tanh),     Dense(1, 3), # Output: Corrections for [g^tt, g^rr, g^ϕϕ] )</p><pre><code class="nohighlight hljs">
 We will treat the corrections as multiplicative for this first case, as follows: 
</code></pre><p>julia g = [       -f^(-1)<em>f<em>tt</em>NN_correction 0 0 0;       0 f</em>f<em>rr</em>NN<em>correction 0 0;       0 0 0 0;       0 0 0 r^(-2)*f</em>ϕϕ<em>NN</em>correction     ]</p><pre><code class="nohighlight hljs">
This Neural Network has only 10 parameters: 
</code></pre><p>julia</p><h1 id="Chain("><a class="docs-heading-anchor" href="#Chain(">Chain(</a><a id="Chain(-1"></a><a class="docs-heading-anchor-permalink" href="#Chain(" title="Permalink"></a></h1><h1 id="layer_1-Dense(1-1,-tanh),-#-2-parameters"><a class="docs-heading-anchor" href="#layer_1-Dense(1-1,-tanh),-#-2-parameters">layer_1 = Dense(1 =&gt; 1, tanh),      # 2 parameters</a><a id="layer_1-Dense(1-1,-tanh),-#-2-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#layer_1-Dense(1-1,-tanh),-#-2-parameters" title="Permalink"></a></h1><h1 id="layer_2-Dense(1-1,-tanh),-#-2-parameters"><a class="docs-heading-anchor" href="#layer_2-Dense(1-1,-tanh),-#-2-parameters">layer_2 = Dense(1 =&gt; 1, tanh),      # 2 parameters</a><a id="layer_2-Dense(1-1,-tanh),-#-2-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#layer_2-Dense(1-1,-tanh),-#-2-parameters" title="Permalink"></a></h1><h1 id="layer_3-Dense(1-3),-#-6-parameters"><a class="docs-heading-anchor" href="#layer_3-Dense(1-3),-#-6-parameters">layer_3 = Dense(1 =&gt; 3),            # 6 parameters</a><a id="layer_3-Dense(1-3),-#-6-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#layer_3-Dense(1-3),-#-6-parameters" title="Permalink"></a></h1><h1 id=")-#-Total:-10-parameters,"><a class="docs-heading-anchor" href="#)-#-Total:-10-parameters,">)        # Total: 10 parameters,</a><a id=")-#-Total:-10-parameters,-1"></a><a class="docs-heading-anchor-permalink" href="#)-#-Total:-10-parameters," title="Permalink"></a></h1><h1 id="-plus-0-states."><a class="docs-heading-anchor" href="##-plus-0-states.">#        plus 0 states.</a><a id="-plus-0-states.-1"></a><a class="docs-heading-anchor-permalink" href="##-plus-0-states." title="Permalink"></a></h1><pre><code class="nohighlight hljs">
We initialize the NN weights and biases for the hidden layers, except for the final layer: 
</code></pre><p>julia for (i, layer) in enumerate(NN<em>Conservative</em>params)     if ~isempty(layer)         if i == length(NN<em>Conservative</em>params)  # Final layer             layer.weight .= 0             layer.bias .= 0  # Force output near 0         else  # Hidden layers             layer.weight .= 0.1 * randn(rng, eltype(layer.weight), size(layer.weight))             layer.bias .= 0.1 * randn(rng, eltype(layer.bias), size(layer.bias))         end     end end</p><pre><code class="nohighlight hljs">
When we do this, here&#39;s what we find for the NN parameters (conservative NN) after initialization (but *before* training): 

- `layer_1 = (weight = [0.23716215388290493;;], bias = [0.12095544082478167])`
- `layer_2 = (weight = [0.03983070751935526;;], bias = [-0.16211640815748582])`
- `layer_3 = (weight = [0.0; 0.0; 0.0;;], bias = [0.0, 0.0, 0.0]))`

When you plot the initial solution to the ODEs, we find exact agreement (as expected, since our base model is the Schwarzschild metric!)

![CircularOrbit](CircularOrbit.png)

Now when we plot the predicted metrics and orbit after initialization (but **before** training), we find exact agreement, as expected:

![3Corrections_PreTraining](3Corrections_PreTraining.png)

Our loss function is simply a mean-squared error between the predicted and true waveform: 
</code></pre><p>julia function loss(NN<em>params; saveat=tsteps)     tspan = (saveat[1],saveat[end])     pred</em>soln = solve(remake(prob<em>nn</em>dual, p = NN<em>params, tspan=tspan), Tsit5(),                             saveat = saveat, dt = dt, adaptive=false, verbose = false, sensealg=BacksolveAdjoint(checkpointing=true))     pred</em>waveform<em>real, pred</em>waveform<em>imag = compute</em>waveform(dt<em>data, pred</em>soln, mass_ratio)</p><pre><code class="nohighlight hljs">loss = ( sum(abs2, waveform_real_ecc .- pred_waveform_real))
return loss</code></pre><p>end</p><pre><code class="nohighlight hljs">
When we run our loss function on just the initial solution, we get `2.25e-7`. Now we run the training process, after which we obtain these results: 

![3Correction_PostTraining](3Correction_PostTraining.png)

I ran through 4 iterations: `optimization_increments = [1, 2, 12, 20]`. Over these four iterations, here&#39;s how the weights and biases changed over time: 

!!! warning &quot;Iteration #1 Weights &amp; Biases&quot;
    - `layer_1 = (weight = [0.2371808185363373;], bias = [0.120935736109229])`
    - `layer_2 = (weight = [0.03982656907286769;], bias = [-0.16213122300485072])` 
    - `layer_3 = (weight = [-1.821512530359164e-5; -1.0175274439859679e-5; 8.716160136546225e-7;], bias = [9.8766420116128e-6, 5.723394566465591e-6, 3.481497345221852e-6]))`

!!! warning &quot;Iteration #2 Weights &amp; Biases&quot;
    - `layer_1 = (weight = [0.23718676030213381;], bias = [0.12092385329517617])`
    - `layer_2 = (weight = [0.03983349725191167;], bias = [-0.1621299634300346])`
    - `layer_3 = (weight = [-2.487679834028046e-5; -2.887058705740126e-5; 1.0738885848191339e-6;], bias = [-4.71782709892314e-6, 7.837322991384513e-6, 2.537287450937874e-6]))`

!!! warning &quot;Iteration #12 Weights &amp; Biases&quot;
    - `layer_1 = (weight = [0.2371894925389875;], bias = [0.12093772915528389])`
    - `layer_2 = (weight = [0.03983157793305357;], bias = [-0.16213630211015895])`
    - `layer_3 = (weight = [-1.6052012110502056e-5; -3.96908865801902e-5; -9.619462849749647e-6;], bias = [-2.1939207002792404e-5, 1.500639545614688e-6, -2.168304595713335e-5]))`

!!! warning &quot;Iteration #20 Weights &amp; Biases&quot;
    - `layer_1 = (weight = [0.23718368381374658;], bias = [0.12094224166402442])`
    - `layer_2 = (weight = [0.03983587381877536;], bias = [-0.16213807102352437])`
    - `layer_3 = (weight = [-9.10753409970219e-6; -4.110947128717602e-5; -1.749976849031467e-5;], bias = [-1.7950002563821174e-5, 1.4704911668732934e-5, -1.9016787781020368e-5]))`

Here are the loss function and state variables post-training for the sanity check: 

![State_Variables_PostTraining](State_Variables_PostTraining.png)

![LossFunction_PostTraining](LossFunction_PostTraining.png)

After printing `f_tt_pred`, `f_rr_pred`, and `f_\phi\phi_pred`, the corrections to the $g^{tt}, g^{rr}, g^{\phi\phi}$, we find: 
</code></pre><p>julia julia&gt; f<em>tt</em>pred 400-element Vector{Any}:  0.9999831633432387  0.999983162958138  0.9999831626034161  0.9999831622767038  0.9999831619758125  0.9999831616987213  0.999983161443564  ⋮  0.9999831584900172  0.9999831584900172  0.9999831584900172  0.9999831584900172  0.9999831584900172  0.9999831584900172</p><pre><code class="nohighlight hljs"></code></pre><p>julia f<em>rr</em>pred 400-element Vector{Any}:  1.0000197298726115  1.0000197281342853  1.0000197265330875  1.0000197250583238  1.000019723700115  1.0000197224493381  1.0000197212975706  ⋮  1.000019707965401  1.000019707965401  1.000019707965401  1.000019707965401  1.000019707965401  1.000019707965401</p><pre><code class="nohighlight hljs"></code></pre><p>julia f<em>pp</em>pred 400-element Vector{Any}:  0.9999831223324658  0.99998312159251  0.9999831209109258  0.9999831202831609  0.9999831197050103  0.9999831191725903  0.9999831186823158  ⋮  0.9999831130071919  0.9999831130071919  0.9999831130071919  0.9999831130071919  0.9999831130071919  0.9999831130071919</p><pre><code class="nohighlight hljs">
Thus, the sanity check has been passed for multiplicative corrections for a circular orbit! Now we consider additive corrections!
</code></pre><p>julia</p><h1 id="Base-Metric:-Schwarzschild-Metric"><a class="docs-heading-anchor" href="#Base-Metric:-Schwarzschild-Metric">Base Metric: Schwarzschild Metric</a><a id="Base-Metric:-Schwarzschild-Metric-1"></a><a class="docs-heading-anchor-permalink" href="#Base-Metric:-Schwarzschild-Metric" title="Permalink"></a></h1><p>g = [         -f^(-1)+f<em>tt</em>NN<em>correction 0 0 0;         0 f+f</em>rr<em>NN</em>correction 0 0;         0 0 0 0;         0 0 0 r^(-2)+f<em>ϕϕ</em>NN_correction     ] ```</p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Monday 3 November 2025 01:13">Monday 3 November 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
